<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="css/style.css">
	<link rel="stylesheet" href="css/responsive.css">
	<link rel="stylesheet" href="css/bootstrap5.css">
	<title>Digital Futures in Mind</title>
</head>

<body>

		<!-- Menu Area -->
<header class="navigation">
	<div class="container menu-bar">
		<div class="navbar-brand"><a href="index.html"><img src="images/logo.svg" alt="Logo"></a></div>
		<ul class="navbar">
			<!-- Dropdown-1 -->
			<li>
				<a href="introduction.html">Introduction <span class="dropdown"></span></a>
				<ul>
				  <li><a href="structure.html">0.1 Structure</a></li>
				  <li><a href="how-was-the-report-written.html">0.2 How was the Report Written?</a></li>
				  <li><a href="what-recommendations-does-the-report-make.html">0.3 What Recommendations Does the Report Make?</a></li>
				  <li><a href="a-note-on-terminology.html">0.4 A Note on Terminology</a></li>
				  <li><a href="minding-language-about-mental-health-and-technology.html">0.5 Minding Language about Mental Health and Technology</a></li>
				</ul>
			  </li>
			 <!-- Dropdown-2 -->
			 <li>
				<a href="rising-automation-in-mental-health.html">Rising Automation in Mental Health <span class="dropdown"></span></a>
				<ul>
				  <li><a href="crisis-support-and-mental-health-care.html">1.1 What are the different ways technology is used in crisis support and mental health care?</a></li>
				  <li><a href="benefits-noted-in-research.html">1.2 Benefits Noted in Research</a></li>
				  <li>
					<a href="psychiatric-intervention-and-Other-coercive-measures.html" >1.3 Digitising Involuntary Psychiatric Intervention and Other Coercive Measures <span class="dropdown"></span></a>
					<ul>
					  <li><a href="ai-based-suicide-alerts-and-self-harm-surveillance.html">1.3.1 AI-based Suicide Alerts and Self-harm Surveillance</a></li>
					  <li><a href="digitising-mental-health-law.html">1.3.2 ‘Digitising mental health law’</a></li>
					  <li><a href="power-and-coercion-in-mental-health.html">1.3.3 Power and Coercion in Mental Health</a></li>
					</ul>
				  </li>
				  <li>
					<a href="biometric-monitoring-technologies.html">1.4 Biometric Monitoring Technologies <span class="dropdown"></span></a>
					<ul>
					  <li><a href="biometric-and-digital-turn.html">1.4.1 Power and Justice in the Biometric and Digital Turn</a></li>
					  <li><a href="biometric-monitoring-in-mental-health-settings.html">1.4.2 Governing the Future of Biometric Monitoring in Mental Health Settings</a></li>
					</ul>
				  </li>
				  <li><a href="experience-of-extreme-distress-and-disability.html">1.5 Elevating the Perspective of People with Lived Experience of Extreme Distress and Disability</a></li>
				</ul>
			  </li>
			<!-- Dropdown-3 -->
			  <li>
				<a href="themes-for-public-governance.html">Themes for Public Governance <span class="dropdown"></span></a>
				<ul>
				  <li>
					<a href="privacy.html">2.1 Privacy <span class="dropdown"></span></a>
					<ul >
					  <li><a href="ad-tech-and-predictive-public-health-surveillance.html">2.1.1 Ad-Tech and Predictive Public Health Surveillance</a></li>
					  <li><a href="privacy-and-monetisation-of-sensitive-personal-data.html">2.1.2 Privacy and Monetisation of Sensitive Personal Data</a></li>
					  <li><a href="data-theft-and-data-trafficking.html">2.1.3 Data Theft and Data Trafficking</a></li>
					  <li><a href="privacy-and-discrimination.html">2.1.4 Privacy and Discrimination</a></li>
					  <li><a href="data-protection-law.html">2.1.5 Data Protection Law</a></li>
					  <li><a href="informed-consent.html">2.1.6 Informed Consent</a></li>
					</ul>
				  </li>
				  <li>
					<a href="accountability.html" >2.2 Accountability <span class="dropdown"></span></a>
					<ul >
					  <li><a href="privatisation-and-accountability.html">2.2.1 Privatisation and Accountability</a></li>
					</ul>
				  </li>
				  <li>
					<a href="safety-and-security.html">2.3 Safety and security <span class="dropdown"></span></a>
					<ul >
					  <li><a href="safety.html">2.3.1 Safety</a></li>
						<li><a href="security.html">2.3.2 Security</a></li>
					</ul>
				  </li>
				  <li>
					<a href="non-discrimination-and-equity.html">2.4 Non-Discrimination and Equity <span class="dropdown"></span></a>
					<ul >
					  <li><a href="non-discrimination-and-the-prevention-of-bias.html">2.4.1 Non-discrimination and the Prevention of Bias</a></li>
						<li><a href="fairness.html">2.4.2 Fairness</a></li>
							<li><a href="equality.html">2.4.3 Equality</a></li>
								<li><a href="inclusive-design.html">2.4.4 Inclusive Design – Emancipatory? Participatory?</a></li>
									<li><a href="access-to-technology.html">2.4.5 Access to Technology</a></li>
					</ul>
				  </li>
				  <li>
					<a href="human-control-of-technology.html">2.5 Human control of technology <span class="dropdown"></span></a>
					<ul >
					  <li><a href="human-review-of-automated-decision.html">2.5.1 Human Review of Automated Decision</a></li>
						<li><a href="automated-decision-making.html">2.5.2 Ability to Opt-Out of Automated Decision-Making</a></li>
					</ul>
				  </li>
				  <li>
					<a href="professional-responsibility.html">2.6 Professional responsibility <span class="dropdown"></span></a>
					<ul >
					  <li><a href="multi-disciplinary-and-participatory-collaboration.html">2.6.1 Multi-disciplinary and Participatory Collaboration</a></li>
						<li><a href="scientific-integrity.html">2.6.2 Scientific Integrity and Testing Claims</a></li>
							<li><a href="techno-solutionism.html">2.6.3 Against Hype and ‘Techno-solutionism’</a></li>
								<li><a href="responsible-design.html">2.6.4 Responsible Design, Including Consideration of Long-Term Effects</a></li>
					</ul>
				  </li>
				  <li>
					<a href="transparency-and-explainability.html">2.7 Transparency and explainability <span class="dropdown"></span></a>
					<ul >
					  <li><a href="open-source-data-and-algorithms.html">2.7.1 Open-Source Data and Algorithms</a></li>
						<li><a href="other-issues-of-transparency-and-explainability.html">2.7.2 Other Issues of Transparency and Explainability</a></li>
					</ul>
				  </li>
				  <li>
					<a href="public-interest-and-societal-good.html">2.8 Promotion of Public Interest and Societal Good <span class="dropdown"></span></a>
					<ul >
					  <li><a href="automation.html">2.8.1 Automation, Undermining Face-to-Face Care, and the Risk of Depersonalisation</a></li>
						<li><a href="expanding-the-frame.html">2.8.2 Expanding the Frame from the Individual to the Social</a></li>
					</ul>
				  </li>
				  <li><a href="international-human-rights.html">2.9 International Human Rights</a></li>
				  <li><a href="future-efforts.html">2.10 Future Efforts</a></li>

				</ul>
			  </li>
		</ul>
		<div class="input-box">
			<input type="text" placeholder="" />
			<div class="search">
				<img src="images/search.png" alt="Search" class="search-icon">
			</div>
			<img src="images/cross-white.png" alt="cross" class="close-icon">
		</div>
</div>
</header>

<!-- =========Mobile Menu============ -->
<header class="mobile-menu">
	<a href="index.html"><img src="images/logo.svg" alt="Logo"></a>
	<input type="checkbox" id="main-nav-check" />
<div id="menu">
<label for="main-nav-check" class="toggle" onclick="" title="Close">&times;</label>
<ul>
	<li><a href="index.html">Home</a></li>
	<li><a href="introduction.html">Introduction</a> <label for="fof" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
		<input type="checkbox" id="fof" class="sub-nav-check" />
		<ul id="fof-sub" class="sub-nav">
			<li class="sub-heading">Introduction <label for="fof" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
			<li><a href="structure.html">0.1 Structure</a></li>
			<li><a href="how-was-the-report-written.html">0.2 How was the Report Written?</a></li>
			<li><a href="what-recommendations-does-the-report-make.html">0.3 What Recommendations Does the Report Make?</a></li>
			<li><a href="a-note-on-terminology.html">0.4 A Note on Terminology</a></li>
			<li><a href="minding-language-about-mental-health-and-technology.html">0.5 Minding Language about Mental Health and Technology</a></li>
		</ul>
	</li>
	<li><a href="rising-automation-in-mental-health.html">Rising Automation in Mental Health</a> <label for="fast-apps" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
		<input type="checkbox" id="fast-apps" class="sub-nav-check" />
		<ul id="fast-apps-sub" class="sub-nav">
			<li class="sub-heading">Rising Automation in Mental Health <label for="fast-apps" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
			<li><a href="crisis-support-and-mental-health-care.html">1.1 What are the different ways technology is used in crisis support and mental health care?</a></li>
			<li><a href="benefits-noted-in-research.html">1.2 Benefits Noted in Research</a></li>
			<li><a href="psychiatric-intervention-and-Other-coercive-measures.html">1.3 Digitising Involuntary Psychiatric Intervention and Other Coercive Measures</a> <label for="fof-portfolio" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="fof-portfolio" class="sub-nav-check" />
				<ul id="fof-portfolio-sub" class="sub-nav">
					<li class="sub-heading">1.3 Digitising Involuntary Psychiatric Intervention and Other Coercive Measures <label for="fof-portfolio" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="ai-based-suicide-alerts-and-self-harm-surveillance.html">1.3.1 AI-based Suicide Alerts and Self-harm Surveillance</a></li>
					<li><a href="digitising-mental-health-law.html">1.3.2 ‘Digitising mental health law’</a></li>
					<li><a href="power-and-coercion-in-mental-health.html">1.3.3 Power and Coercion in Mental Health</a></li>
				</ul>
			</li>
			<li><a href="biometric-monitoring-technologies.html">1.4 Biometric Monitoring Technologies</a> <label for="fof-services" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="fof-services" class="sub-nav-check" />
				<ul id="fof-services-sub" class="sub-nav">
					<li class="sub-heading">1.4 Biometric Monitoring Technologies <label for="fof-services" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="biometric-and-digital-turn.html">1.4.1 Power and Justice in the Biometric and Digital Turn</a></li>
					<li><a href="biometric-monitoring-in-mental-health-settings.html">1.4.2 Governing the Future of Biometric Monitoring in Mental Health Settings</a></li>
				</ul>
			</li>
			<li><a href="experience-of-extreme-distress-and-disability.html">1.5 Elevating the Perspective of People with Lived Experience of Extreme Distress and Disability</a></li>
		</ul>
	</li>
	<li><a href="themes-for-public-governance.html">Themes for Public Governance</a> <label for="public-apps" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
		<input type="checkbox" id="public-apps" class="sub-nav-check" />
		<ul id="public-apps-sub" class="sub-nav">
			<li class="sub-heading">Themes for Public Governance<label for="public-apps" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
			<li><a href="privacy.html">2.1 Privacy</a> <label for="public-portfolio" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-portfolio" class="sub-nav-check" />
				<ul id="public-portfolio-sub" class="sub-nav">
					<li class="sub-heading">2.1 Privacy <label for="public-portfolio" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="ad-tech-and-predictive-public-health-surveillance.html">2.1.1 Ad-Tech and Predictive Public Health Surveillance</a></li>
					<li><a href="privacy-and-monetisation-of-sensitive-personal-data.html">2.1.2 Privacy and Monetisation of Sensitive Personal Data</a></li>
					<li><a href="data-theft-and-data-trafficking.html">2.1.3 Data Theft and Data Trafficking</a></li>
					<li><a href="privacy-and-discrimination.html">2.1.4 Privacy and Discrimination</a></li>
					<li><a href="data-protection-law.html">2.1.5 Data Protection Law</a></li>
					<li><a href="informed-consent.html">2.1.6 Informed Consent</a></li>
				</ul>
			</li>
			<li><a href="accountability.html">2.2 Accountability</a> <label for="public-acc" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-acc" class="sub-nav-check" />
				<ul id="public-acc-sub" class="sub-nav">
					<li class="sub-heading">2.2 Accountability <label for="public-acc" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="privatisation-and-accountability.html">2.2.1 Privatisation and Accountability</a></li>
				</ul>
			</li>
			<li><a href="safety-and-security.html">2.3 Safety and security</a> <label for="public-Safety-security" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-Safety-security" class="sub-nav-check" />
				<ul id="public-Safety-security-sub" class="sub-nav">
					<li class="sub-heading">2.2 Accountability <label for="public-Safety-security" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="safety.html">2.3.1 Safety</a></li>
					<li><a href="security.html">2.3.2 Security</a></li>
				</ul>
			</li>
			<li><a href="non-discrimination-and-equity.html">2.4 Non-Discrimination and Equity</a> <label for="public-equity" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-equity" class="sub-nav-check" />
				<ul id="public-equity-sub" class="sub-nav">
					<li class="sub-heading">2.4 Non-Discrimination and Equity <label for="public-equity" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="non-discrimination-and-the-prevention-of-bias.html">2.4.1 Non-discrimination and the Prevention of Bias</a></li>
					<li><a href="fairness.html">2.4.2 Fairness</a></li>
					<li><a href="equality.html">2.4.3 Equality</a></li>
					<li><a href="inclusive-design.html">2.4.4 Inclusive Design – Emancipatory? Participatory?</a></li>
					<li><a href="access-to-technology.html">2.4.5 Access to Technology</a></li>
				</ul>
			</li>

			<li><a href="human-control-of-technology.html">2.5 Human control of technology</a> <label for="public-human" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-human" class="sub-nav-check" />
				<ul id="public-human-sub" class="sub-nav">
					<li class="sub-heading">2.5 Human control of technology <label for="public-human" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="human-review-of-automated-decision.html">2.5.1 Human Review of Automated Decision</a></li>
					<li><a href="automated-decision-making.html">2.5.2 Ability to Opt-Out of Automated Decision-Making</a></li>
				</ul>
			</li>
			<li><a href="professional-responsibility.html">2.6 Professional responsibility</a> <label for="public-profess" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-profess" class="sub-nav-check" />
				<ul id="public-profess-sub" class="sub-nav">
					<li class="sub-heading">>2.6 Professional responsibility <label for="public-profess" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="multi-disciplinary-and-participatory-collaboration.html">2.6.1 Multi-disciplinary and Participatory Collaboration</a></li>
					<li><a href="scientific-integrity.html">2.6.2 Scientific Integrity and Testing Claims</a></li>
					<li><a href="techno-solutionism.html">2.6.3 Against Hype and ‘Techno-solutionism’</a></li>
					<li><a href="responsible-design.html">2.6.4 Responsible Design, Including Consideration of Long-Term Effects</a></li>
				</ul>
			</li>
			<li><a href="transparency-and-explainability.html">2.7 Transparency and explainability</a> <label for="public-trans" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-trans" class="sub-nav-check" />
				<ul id="public-trans-sub" class="sub-nav">
					<li class="sub-heading">2.7 Transparency and explainability <label for="public-trans" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="open-source-data-and-algorithms.html">2.7.1 Open-Source Data and Algorithms</a></li>
					<li><a href="other-issues-of-transparency-and-explainability.html">2.7.2 Other Issues of Transparency and Explainability</a></li>
				</ul>
			</li>
			<li><a href="public-interest-and-societal-good.html">2.8 Promotion of Public Interest and Societal Good</a> <label for="public-promo" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-promo" class="sub-nav-check" />
				<ul id="public-promo-sub" class="sub-nav">
					<li class="sub-heading">2.8 Promotion of Public Interest and Societal Good <label for="public-promo" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="automation.html">2.8.1 Automation, Undermining Face-to-Face Care, and the Risk of Depersonalisation</a></li>
					<li><a href="expanding-the-frame.html">2.8.2 Expanding the Frame from the Individual to the Social</a></li>
				</ul>
			</li>
			<li><a href="international-human-rights.html">2.9 International Human Rights</a></li>
			<li><a href="future-efforts.html">2.10 Future Efforts</a></li>
		</ul>
	</li>

</ul>
<div class="input-box">
	<input type="text" placeholder="" />
	<div class="search">
		<img src="images/search.png" alt="Search" class="search-icon">
	</div>
	<img src="images/cross-white.png" alt="cross" class="close-icon">
</div>
</div>
<div id="header">
	<label for="main-nav-check" class="toggle" onclick="" title="Menu">&#x2261;</label>
</div><!-- closing "#header" -->
</header>
	<!-- Content Area -->
	<div class="container">
		<div class="row">
			<main>
				<aside class="col-lg-3 col-12 sidebar-left">
					<ol>
						<li>
							<a href="about.html">About</a>
						</li>
						<li>
							<a href="foreword.html">Foreword</a>
						</li>
						<li>
							<a href="introduction.html" class="active">Introduction</a>
						</li>
						<li>
							<a href="recommendations.html">Recommendations</a>
						</li>
						<li>
							<a href="note-on-terminology.html">A note on Terminology</a>
						</li>
						<li>
							<a href="rising-automation-in-mental-health.html">Rising Automation in Mental Health</a>
						</li>
						<li>
							<a href="digitising-involuntary-psychiatric-intervention.html">digitising Involuntary Psychiatric Intervention</a>
						</li>
						<li>
							<a href="biometric-monitoring-technologies.html">Biometric Monitoring Technologies</a>
						</li>
						<li>
							<a href="distress-and-disability.html">Elevating the Perspective of People with Lived Experience of Extreme Distress and Disability</a>
						</li>
						<li>
							<a href="themes-for-public-governance.html">Themes for Public Governance</a>
						</li>
						<li>
							<a href="conclusion.html">Conclusion</a>
						</li>
					</ol>
				</aside>
				<section class="col-lg-9 col-12 sidebar-middle">
					<div class="content-pane2">
						<h2 id="part2-subone">2.4.1 Non-discrimination and the Prevention of Bias</h2>
				<p>The potential for algorithmic bias or discrimination is a well-documented issue.
					Much public discussion in this area has focused on gender, race and socio-economic
					inequality<sup>304</sup>. However, disability, including mental health and psychosocial disability, ‘has
					been largely omitted from the AI-bias conversation’.<sup>305</sup> Whitaker and colleagues have
					argued that ‘patterns of marginalization [concerning disability] are imprinted in the data
					that shapes AI systems, and embed these histories in the logics of AI’.<sup>306</sup> For example,
					Ben Hutchinson and colleagues at Google, demonstrated that social attitudes casting
					disability as bad and even violent – particularly in regard to mental health – were encoded
					in AI systems designed to detect hate speech and identify negative/positive sentiment
					in written text.<sup>307</sup> The ‘machine-learned model to moderate conversations’, according
					to Hutchinson and colleagues, classifies texts which mention disability and particularly
					references to mental health as more ‘toxic’, while ‘a machine-learned sentiment analysis
					model rates texts which mention disability as more negative’.<sup>308</sup> Such studies highlight
					how biased datasets create biased algorithms, which can have major consequences for
					people’s lives, as the next example shows. </p>

				
				<div class="skydivbox">
					<h2>CASE STUDY: Disability-Discrimination in Automated Hiring Programs</h2>
					<p>Mr Kyle Behm was a high-achieving university student in the US.<sup>309</sup> He was refused a
						minimum-wage job after reportedly being ‘red-lighted’ by the automated personality test
						he’d taken as part of his job application. Mr Behm had previously accessed mental health
						services and was diagnosed with a mental health condition. He only became aware of the
						‘red-lighting’ after being informed by a friend who happened to work for the employer.
						Mr Behm applied for several other minimum-wage positions but was again seemingly
						‘red-lighted’ following automated personality testing. Mr Behm’s father, a lawyer,
						publicised the widespread use of the job applicant selection program and launched a
						class-action suit alleging that the exam hiring process was unlawful. He argued that the
						process violated the Americans with Disabilities Act of 1990 (‘ADA’) by being equivalent
						to a medical exam, for which its use under the ADA for hiring purposes would be illegal.
						In November 2017, the US retailer Lowe’s announced a change to online application
						processes for retail employees ‘to ensure people with mental health disabilities can more
						readily be considered for opportunities with Lowe’s’.<sup>310</sup></p>
				</div>
				<p>This case study is revealing. Mr Behm was seemingly harmed due to data to which he was
					never given access. Nor does it appear that Mr Behm had an easily accessible opportunity
					to contest, explain or investigate the test outcome. Cathy O’Neil argues that this type of
					algorithmic ‘red-lighting’ has the potential to ‘create an underclass of people who will find
					themselves increasingly and inexplicably shut out from normal life’.<sup>311</sup></p>
				<p> One response to biased algorithmic systems has been to focus on creating un-biased
					datasets. Datasets could be made more diverse, the argument goes, to capture diverse
					human experiences. This would avoid negative consequences for people who, through
					the various human and circumstantial complexities in their lives, are considered ‘statistical
					outliers’ for whom algorithmic decision systems are ill-equipped. This approach is certainly
					warranted in some circumstances, where the need for good quality and representative data
					can help avoid biased or discriminatory outcomes.</p>
				<p> However, the aim of creating unbiased datasets will be insufficient in many situations.
					Meredith Broussard criticises this approach as being commonly ‘technochauvinist’ in
					nature.<sup>312</sup> Techno-chauvinism refers here to the false view that technological solutions provide
					‘appropriate and adequate fixes to the deeply human problem of bias and discrimination’.<sup>313</sup></p>
				<p> Representative and high-quality datasets will be important in some instances but
					Broussard’s criticism suggests that there is a second major category of discrimination at
					play: namely, discrimination perpetuated by human systems and institutions using data
					concerning mental health. Examples might include insurance companies discriminating
					against people based on data showing that they accessed mental health services at one
					time,<sup>314</sup> or police and border authorities discriminating against people based on non-criminal data concerning an individual’s engagement with mental health services, as the
					next example shows.</p>

				<div class="skydivbox">
					<h2>CASE STUDY: Discrimination by Human Systems: Police, Surveillance, and Mental Health</h2>
					<p>In 2018, in Florida, in the US, the state legislature authorised the collection and
						digitisation of certain types of student mental health data and its distribution through
						a statewide police database.<sup>315</sup> The purported aim was to prevent gun violence.
						The health-related information would be reportedly combined with social media
						monitoring activities, the precise nature of which was undisclosed. Journalists later
						reported that the type of information under consideration included ‘more than 2.5
						million records related to those who received psychiatric examinations’ under the
						Florida Mental Health Act of 1971.<sup>316</sup> The Department was reportedly considering
						including ‘records for over 9 million children in foster care, diagnosis and treatment
						records for substance abusers… and reports on students who were bullied and
						harassed because of their race or sexual orientation’.<sup>317</sup></p>
				</div>
				<p>This example suggests that no amount of ‘unbiased datasets’ will offset the discriminatory
					premise of various digital initiatives, which are designed to intervene in the lives of persons
					with lived experience and disability on an unequal basis with others.</p>
				<p>Discriminatory impacts are also more likely as algorithmic and data-driven technologies
					are applied in settings affecting marginalised populations. This includes settings in which
					there are broader constraints on individuals’ agency, including cumulative effects of
					disadvantage. This could include ethnic and racial minorities, people facing involuntary
					psychiatric intervention, families or individuals facing housing insecurity, returning
					veterans, people with addiction, the previously or presently incarcerated, and migrants
					and asylum-seekers.<sup>318</sup> LLana James points to these concerns when she asks: ‘How will
					data labelled as Black, poor, disabled or all three impact a person’s insurance rates?<sup>319</sup>
					James argues that current laws (writing in Canada) do not appear to protect health
					service recipients and patients and calls for updated data laws to protect against ‘the
					perils of monetized data and the discriminatory algorithms they are generating’.<sup>320</sup></p>
				<p>Regarding insurance, Access Now have expanded on James’ point regarding exclusion
					and insurance-based discrimination, noting that:</p>
				<div class="benifit-box">
					<ul>
						<li>[i]nsurance actors have for some time perceived digital forensics as an economical
							means of constructing more informed risk assessments regarding social behaviour
							and lifestyles. This type of granular data on driving skills sets and perhaps on
							attitudinal traits around the driving task (derived from AI assisted driving technology)
							could allow the insurers to more accurately metricise risk. For an individual, the
							consequences are fairly obvious in rising premium costs or even in some cases
							no access to insurance. However, for society the long-term impacts may be less
							apparent in that it may result in cohorts of people being deemed uninsurable and
							therefore denied access to the roads.<sup>321</sup></li>
					</ul>
				</div>

				<p>This point is concerning in the mental health context, and the emergence in recent years of
					partnerships between insurance companies and mental health technology companies<sup>322</sup> and
					other insurance company initiatives concerning mental health-related data warrant scrutiny.<sup>323</sup></p>
				<p> The likelihood of disability-based discrimination will be compounded when data scientists,
					technologists, tech entrepreneurs, clinical innovators, and so on, are not aware of the
					potential for discrimination using data concerning mental health. Consider the following
					claims being made in the ‘emotion recognition’ industry in China.</p>
				<div class="skydivbox">
					<h2>CASE STUDY: Discrimination by Human Systems: Police, Surveillance, and Mental Health</h2>
					<p>Advocacy group Article 19 recently surveyed 27 Chinese companies whose emotion
						recognition technologies are being trialled in three areas: public security, driving safety,
						and educational settings.<sup>324</sup> Companies like Taigusys Computing and EmoKit refer to
						autism, schizophrenia and depression as conditions they can diagnose and monitor
						using ‘micro-expression recognition’. The authors of the Article 19 report argued that
						data harms concerning mental health remain unaddressed, as does the lack of robust
						scientific evidence for these technologies:</p>
					<p class="sm-padd-gap">While some emotion recognition companies allege they can detect sensitive
						attributes, such as mental health conditions and race, none have addressed
						the potentially discriminatory consequences of collecting this information in
						conjunction with emotion data… Firms that purportedly identify neurological
						diseases and psychological disorders from facial emotions fail to account for
						how their commercial emotion recognition applications might factor in these
						considerations when assessing people’s emotions in non-medical settings, like
						classrooms.<sup>325</sup></p>
				</div>
				<p>AI Now Institute, an interdisciplinary research centre examining artificial intelligence and
					society, have called for a ban on technology designed to recognise people’s emotions
					concerning ‘important decisions that impact people’s lives and access to opportunities’.<sup>326</sup>
					This scope would surely extend to automated forms of diagnosis or proxy-diagnosis of
					cognitive impairments or mental health conditions. The proposed ban could apply to
					decisions concerning hiring, workplace assessment, insurance pricing, pain assessments
					or education performance. AI Now base their recommendation on two concerns: 1) the
					often-baseless scientific foundations of emotion recognition, and 2) the potential for bias
					and discrimination in the resulting decisions.<sup>327</sup></p>
						
				<p>Emotion or ‘affect’ recognition technology such as facial recognition technology raise
					important issues for this report. At least three points relating to non-discrimination and
					the mental health context are worth noting:</p>
				<div class="benifit-box">
					<ul>
						<li>First, traditional facial recognition processes based on ‘basic emotions theory’ have been
							discredited as pseudoscientific.<sup>328</sup></li>
						<li>Second, and relatedly, there appear to be strong grounds to call for a moratorium on the
							use of affect technologies like facial recognition in any important decisions concerning
							mental health, including imputing intellectual and cognitive impairments or psychiatric
							diagnoses. Not only are the scientific foundations of such approaches generally
							spurious, which is probably reason enough to justify a moratorium, but the potential for
							discrimination based on impairment ascribed in this way is very poorly understood.</li>
						<li>Third, few people in broader debate about affect or emotion recognition technologies
							such as facial recognition appear to be engaging with the expansion of behavioural
							sensing, ‘digital phenotyping’ and other forms of biometric monitoring and surveillance
							in the mental health context. The scientific basis of claims being made about behavioural
							sensing are currently being explored in the fields of psychiatry and psychology,
							with studies appearing in leading psychiatric and psychology journals. This scientific
							exploration warrants greater dialogue between activity on affect recognition technology
							in the mental health context and the broader debates about facial recognition technology
							and other biometric technologies in society more broadly.<sup>329</sup></li>
					</ul>
				</div>
				<p>There are important differences between the motives and claims of commercial actors
					who are promoting affect or emotion recognition technology, and that of biometric
					monitoring in clinical studies conducted by mental health researchers—and there
					are major differences in the regulatory frameworks affecting each. In general, health
					research is far more tightly regulated, with more entrenched infrastructure for upholding
					ethical research involving humans. Although not without serious problems, including
					the interference of private industry with academic research,330<sup>330</sup> and the growing reliance
					of universities on the private sector to fund research,331<sup>331</sup> the scholarly health research
					infrastructure appears better developed for the purposes of ethical oversight, than many
					private sector uses of affect recognition technologies, including where those technologies
					are sold to government agencies, such as police agencies and border authorities.</p>
				<p>Nevertheless, there are many examples of overlap between commercial and clinical activities
					in the digital mental health context,<sup>332</sup> and public scrutiny is required of clinical or scholarly
					claims about what behaviour can convey about a person’s inner-world. It is not possible in this
					report to examine the claims being made about psychiatric biometric monitoring. Instead, the
					aim in this section is to draw attention to poorly understood potential for discrimination and
					bias in the use of such technologies in the mental health and disability context.</p>
				<p>Concerns about discrimination need not relate to algorithmic systems. For example, a coalition
					of Australian organisations representing people with lived experience and psychosocial
					disability called for a suspension of a national electronic health records scheme, citing fears of
					discrimination if personal mental health histories were stolen, leaked or sold.<sup>333</sup> Previous case
					studies cited throughout the report demonstrate how such discrimination might occur.</p>
					
				<p>One important step to preventing harms caused by data concerning mental health and
					disability – whether leaked, stolen or traded – is to strengthen non-discrimination rules
					concerning mental health and psychosocial disability.<sup>334</sup> National discrimination laws may
					require amendments to ensure that discrimination on mental health grounds by online
					businesses is covered.<sup>335</sup> Such amendments would be consistent with the goals and
					legislative history of anti-discrimination laws and would remove ambiguity regarding the
					status of websites, social media platforms and other online businesses.<sup>336</sup> Remedies for
					individuals who are aggrieved by discriminatory behaviour and practices are also likely to
					require strengthening, including ensuring substantive, verifiable, auditable standards of
					non-discrimination in the use of algorithmic and data-driven technologies</p>
						
							<div class="sm-txt">
					<ul>
						<li>303 James (n 157).</li>
						<li>304 Virginia Eubanks, Automating Inequality (Macmillan, 2018); Cathy O’Neil, Weapons of Math Destruction: How Big Data Increases Inequality
							and Threatens Democracy (Crown, 2016).</li>
						<li>305 Whittaker et al (n 1) p.8.</li>
						<li>306 Whittaker et al (n 1) p.8.</li>
						<li>307 Ben Hutchinson et al, ‘Social Biases in NLP Models as Barriers for Persons with Disabilities’ [2020] arXiv:2005.00813 [cs] <a href="http://arxiv.org/abs/2005.00813">http://arxiv.org/abs/2005.00813</a>.</li>
						<li>308 Ibid.</li>
						<li>309 This account draws from: O’Neil, Weapons of Math Destruction (n 307).</li>
						<li>310 Letter from Lowes and Bazelon Center for Mental Health Law (n 269).</li>
						<li>311 Cathy O’Neil, ‘How Algorithms Rule Our Working Lives | Cathy O’Neil’, The Guardian (online, 1 September 2016) <a href="https://www.theguardian.com/science/2016/sep/01/how-algorithms-rule-our-working-lives">https://www.theguardian.com/science/2016/sep/01/how-algorithms-rule-our-working-lives</a>.</li>
						<li>312 Meredith Broussard, Artificial Unintelligence: How Computers Misunderstand the World (MIT Press, 2018).</li>
						<li>313 Fjeld et al (n 85) p.48.</li>
						<li>314 Victorian Equal Opportunity & Human Rights Commission, Fair-Minded Cover: Investigation into Mental Health Discrimination in Travel
							Insurance. (2019).</li>
						<li>315 Scott Travis, ‘Florida Wants to Amass Reams of Data on Students’ Lives’, sun-sentinel.com (2019) <a href="https://www.sun-sentinel.com/local/broward/parkland/florida-school-shooting/fl-ne-school-shooting-database-deadline-20190709-i4ocsmqeivdmrhpauhyaplg52u-story.html">https://www.sun-sentinel.com/local/broward/parkland/florida-school-shooting/fl-ne-school-shooting-database-deadline-20190709-i4ocsmqeivdmrhpauhyaplg52u-story.html</a>.</li>
						<li>316 Ibid.</li>
						<li>317 Ibid.</li>
						<li>318 Eubanks (n 307).</li>
						<li>319 James (n 157).</li>
						<li>320 Ibid.</li>
						<li>321 Martin Cunneen, Martin Mullins and Finbarr Murphy, ‘Artificial Intelligence Assistants and Risk: Framing a Connectivity Risk Narrative’
							(2020) 35(3) AI & SOCIETY 625, 627</li>
						<li>322 See eg. AIA Australia, ‘AIA AND MENTEMIA: Practical tips and techniques to help you take control of your mental wellbeing’
							<a href="https://www.aia.com.au/en/individual/mentemia.html">https://www.aia.com.au/en/individual/mentemia.html</a> (accessed 14/10/22).
						</li>
						<li>323 For research on the political economy of insurance technology, or ‘insurtech’ see <a href="http://www.jathansadowski.com/">http://www.jathansadowski.com/</a> (accessed 14/10/21).</li>
						<li>324 Article 19, ‘Emotional Entanglement: China’s Emotion Recognition Market and Its Implications for Human Rights’ (January 2021) 19
							<a href="https://www.article19.org/wp-content/uploads/2021/01/ER-Tech-China-Report.pdf">https://www.article19.org/wp-content/uploads/2021/01/ER-Tech-China-Report.pdf</a>.
						</li>
						<li>325 Ibid.</li>
						<li>326 Kate Crawford et al, AI Now 2019 Report (AI Now Institute, December 2019) p.6 <a href="https://ainowinstitute.org/AI_Now_2019_Report.html">https://ainowinstitute.org/AI_Now_2019_Report.html</a>.</li>
						<li>327 Ibid.</li>
						<li>328 For review of evidence, see: Lisa Feldman Barrett, How Emotions Are Made: The Secret Life of the Brain (Houghton Mifflin Harcourt, 2017)
							13–24.</li>
						<li>329 See eg. Cosgrove et al (n 69); Friesen (n 76); Mohr, Shilton and Hotopf (n 72); Martinez-Martin et al (n 69).</li>
						<li>330 Joanna Moncrieff, The Bitterest Pills: The Troubling Story of Antipsychotic Drugs (Palgrave Macmillan, 2013th edition, 2013).</li>
						<li>331 Cris Shore and Laura McLauchlan, ‘“Third Mission” Activities, Commercialisation and Academic Entrepreneurs’ (2012) 20(3) Social
							Anthropology 267; K Philpott, L Dooley, C O’Reilly and G Lupton ‘The entrepreneurial university: examining the underlying academic tensions’
							(2010) 31 Technovation 161– 70.</li>
						<li>332 Adam Rogers, ‘Star Neuroscientist Tom Insel Leaves the Google-Spawned Verily for ... a Startup?’ (11 May 2017) Wired
							<a href="https://www.wired.com/2017/05/star-neuroscientist-tom-insel-leaves-google-spawned-verily-startup/">https://www.wired.com/2017/05/star-neuroscientist-tom-insel-leaves-google-spawned-verily-startup/</a>.
						</li>
						<li>333 ‘Joint Letter to Minister Hunt – My Health Record: Call to Suspend My Health Record Roll Out’Letter from Shauna Gaebler et al, 7 August
							2018 <a href="http://being.org.au/2018/08/joint-letter-to-minister-hunt-my-health-records/">http://being.org.au/2018/08/joint-letter-to-minister-hunt-my-health-records/</a>.</li>
					</ul>
				</div>
						</div>
				</section>
			
		
				</main>
	</div>
	<!-- Footer Area -->
	<footer>
		<article class="foot-top">
			<div class="container">
				<div class="row">
					<div class="foot-top-area">
						<div class="arrow-plc">
							<a href="index.html" rel="prev">
							<div class="icon-area">
								<svg xmlns="http://www.w3.org/2000/svg" width="18.414" height="12.828" viewBox="0 0 18.414 12.828">
									<g id="Group_11" data-name="Group 11" transform="translate(282.914 497.914) rotate(180)">
									  <line id="Line_1" data-name="Line 1" x2="16" transform="translate(265.5 491.5)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
									  <line id="Line_2" data-name="Line 2" x2="5" y2="5" transform="translate(276.5 486.5)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
									  <line id="Line_3" data-name="Line 3" y1="5" x2="5" transform="translate(276.5 491.5)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
									</g>
								  </svg>
							</div>
							<div class="foot-title prev">
								<div class="foot-direction"><a href="non-discrimination-and-equity.html">Previous</a></div>
								<div class="foot-link"><a href="non-discrimination-and-equity.html">Non-Discrimination and Equity</a></div>
							</div>
							</a>
						</div>
						<div class="arrow-plc">
							<a href="index.html" rel="next">
								<div class="foot-title next">
									<div class="foot-direction"><a href="foreword.html">Next</a></div>
									<div class="foot-link"><a href="foreword.html">Foreword</a></div>
								</div>
								<div class="icon-area">
									<svg xmlns="http://www.w3.org/2000/svg" width="18.414" height="12.828" viewBox="0 0 18.414 12.828">
										<g id="Group_11" data-name="Group 11" transform="translate(1 1.414)">
										  <line id="Line_1" data-name="Line 1" x2="16" transform="translate(0 5)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
										  <line id="Line_2" data-name="Line 2" y1="5" x2="5" transform="translate(11 5)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
										  <line id="Line_3" data-name="Line 3" x2="5" y2="5" transform="translate(11)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
										</g>
									  </svg>
								</div>
							</a>
						</div>
				</div>
					</div>
					</div>
		</article>
		<article class="foot-bottom"><a href="https://www.suncoastwebsolutions.com.au/services/web-design">Website Design</a> | <a href="https://www.suncoastwebsolutions.com.au/services/domain-web-hosting">Website Hosting</a> | Copyright © 2023 All rights reserved​ <a href="#">Digital Futures in Mind</a></article>
		<div class="scroll-to-top-btn"><svg viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><defs><style>.cls-1{fill:none;stroke:#fff;stroke-linecap:round;stroke-linejoin:round;stroke-width:2px;}</style></defs><title/><g id="arrow-top"><line class="cls-1" x1="15.87" x2="16.13" y1="3" y2="29"/><line class="cls-1" x1="15.87" x2="20.91" y1="3" y2="6.95"/><line class="cls-1" x1="15.87" x2="10.91" y1="3" y2="7.05"/></g></svg></div>
</footer>
	
	
<script src="js/jquery.min.js"></script>
<script src="js/bootstrap5.js"></script>
<script src="js/global.js"></script>

</body>

</html>