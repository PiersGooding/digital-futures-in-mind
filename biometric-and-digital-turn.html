<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="css/style.css">
	<link rel="stylesheet" href="css/responsive.css">
	<link rel="stylesheet" href="css/bootstrap5.css">
	<title>Digital Futures in Mind</title>
</head>

<body>

<!-- Menu Area -->
<header class="navigation">
	<div class="container menu-bar">
		<div class="navbar-brand"><a href="index.html"><img src="images/logo.svg" alt="Logo"></a></div>
		<ul class="navbar">
			<!-- Dropdown-1 -->
			<li>
				<a href="introduction.html">Introduction <span class="dropdown"></span></a>
				<ul>
				  <li><a href="structure.html">0.1 Structure</a></li>
				  <li><a href="how-was-the-report-written.html">0.2 How was the Report Written?</a></li>
				  <li><a href="what-recommendations-does-the-report-make.html">0.3 What Recommendations Does the Report Make?</a></li>
				  <li><a href="a-note-on-terminology.html">0.4 A Note on Terminology</a></li>
				  <li><a href="minding-language-about-mental-health-and-technology.html">0.5 Minding Language about Mental Health and Technology</a></li>
				</ul>
			  </li>
			 <!-- Dropdown-2 -->
			 <li>
				<a href="rising-automation-in-mental-health.html">Rising Automation in Mental Health <span class="dropdown"></span></a>
				<ul>
				  <li><a href="crisis-support-and-mental-health-care.html">1.1 What are the different ways technology is used in crisis support and mental health care?</a></li>
				  <li><a href="benefits-noted-in-research.html">1.2 Benefits Noted in Research</a></li>
				  <li>
					<a href="psychiatric-intervention-and-Other-coercive-measures.html" >1.3 Digitising Involuntary Psychiatric Intervention and Other Coercive Measures <span class="dropdown"></span></a>
					<ul>
					  <li><a href="ai-based-suicide-alerts-and-self-harm-surveillance.html">1.3.1 AI-based Suicide Alerts and Self-harm Surveillance</a></li>
					  <li><a href="digitising-mental-health-law.html">1.3.2 ‘Digitising mental health law’</a></li>
					  <li><a href="power-and-coercion-in-mental-health.html">1.3.3 Power and Coercion in Mental Health</a></li>
					</ul>
				  </li>
				  <li>
					<a href="biometric-monitoring-technologies.html">1.4 Biometric Monitoring Technologies <span class="dropdown"></span></a>
					<ul>
					  <li><a href="biometric-and-digital-turn.html">1.4.1 Power and Justice in the Biometric and Digital Turn</a></li>
					  <li><a href="biometric-monitoring-in-mental-health-settings.html">1.4.2 Governing the Future of Biometric Monitoring in Mental Health Settings</a></li>
					</ul>
				  </li>
				  <li><a href="experience-of-extreme-distress-and-disability.html">1.5 Elevating the Perspective of People with Lived Experience of Extreme Distress and Disability</a></li>
				</ul>
			  </li>
			<!-- Dropdown-3 -->
			  <li>
				<a href="themes-for-public-governance.html">Themes for Public Governance <span class="dropdown"></span></a>
				<ul>
				  <li>
					<a href="privacy.html">2.1 Privacy <span class="dropdown"></span></a>
					<ul >
					  <li><a href="ad-tech-and-predictive-public-health-surveillance.html">2.1.1 Ad-Tech and Predictive Public Health Surveillance</a></li>
					  <li><a href="privacy-and-monetisation-of-sensitive-personal-data.html">2.1.2 Privacy and Monetisation of Sensitive Personal Data</a></li>
					  <li><a href="data-theft-and-data-trafficking.html">2.1.3 Data Theft and Data Trafficking</a></li>
					  <li><a href="privacy-and-discrimination.html">2.1.4 Privacy and Discrimination</a></li>
					  <li><a href="data-protection-law.html">2.1.5 Data Protection Law</a></li>
					  <li><a href="informed-consent.html">2.1.6 Informed Consent</a></li>
					</ul>
				  </li>
				  <li>
					<a href="accountability.html" >2.2 Accountability <span class="dropdown"></span></a>
					<ul >
					  <li><a href="privatisation-and-accountability.html">2.2.1 Privatisation and Accountability</a></li>
					</ul>
				  </li>
				  <li>
					<a href="safety-and-security.html">2.3 Safety and security <span class="dropdown"></span></a>
					<ul >
					  <li><a href="safety.html">2.3.1 Safety</a></li>
						<li><a href="security.html">2.3.2 Security</a></li>
					</ul>
				  </li>
				  <li>
					<a href="non-discrimination-and-equity.html">2.4 Non-Discrimination and Equity <span class="dropdown"></span></a>
					<ul >
					  <li><a href="non-discrimination-and-the-prevention-of-bias.html">2.4.1 Non-discrimination and the Prevention of Bias</a></li>
						<li><a href="fairness.html">2.4.2 Fairness</a></li>
							<li><a href="equality.html">2.4.3 Equality</a></li>
								<li><a href="inclusive-design.html">2.4.4 Inclusive Design – Emancipatory? Participatory?</a></li>
									<li><a href="access-to-technology.html">2.4.5 Access to Technology</a></li>
					</ul>
				  </li>
				  <li>
					<a href="human-control-of-technology.html">2.5 Human control of technology <span class="dropdown"></span></a>
					<ul >
					  <li><a href="human-review-of-automated-decision.html">2.5.1 Human Review of Automated Decision</a></li>
						<li><a href="automated-decision-making.html">2.5.2 Ability to Opt-Out of Automated Decision-Making</a></li>
					</ul>
				  </li>
				  <li>
					<a href="professional-responsibility.html">2.6 Professional responsibility <span class="dropdown"></span></a>
					<ul >
					  <li><a href="multi-disciplinary-and-participatory-collaboration.html">2.6.1 Multi-disciplinary and Participatory Collaboration</a></li>
						<li><a href="scientific-integrity.html">2.6.2 Scientific Integrity and Testing Claims</a></li>
							<li><a href="techno-solutionism.html">2.6.3 Against Hype and ‘Techno-solutionism’</a></li>
								<li><a href="responsible-design.html">2.6.4 Responsible Design, Including Consideration of Long-Term Effects</a></li>
					</ul>
				  </li>
				  <li>
					<a href="transparency-and-explainability.html">2.7 Transparency and explainability <span class="dropdown"></span></a>
					<ul >
					  <li><a href="open-source-data-and-algorithms.html">2.7.1 Open-Source Data and Algorithms</a></li>
						<li><a href="other-issues-of-transparency-and-explainability.html">2.7.2 Other Issues of Transparency and Explainability</a></li>
					</ul>
				  </li>
				  <li>
					<a href="public-interest-and-societal-good.html">2.8 Promotion of Public Interest and Societal Good <span class="dropdown"></span></a>
					<ul >
					  <li><a href="automation.html">2.8.1 Automation, Undermining Face-to-Face Care, and the Risk of Depersonalisation</a></li>
						<li><a href="expanding-the-frame.html">2.8.2 Expanding the Frame from the Individual to the Social</a></li>
					</ul>
				  </li>
				  <li><a href="international-human-rights.html">2.9 International Human Rights</a></li>
				  <li><a href="future-efforts.html">2.10 Future Efforts</a></li>

				</ul>
			  </li>
		</ul>
		<div class="input-box">
			<input type="text" placeholder="" />
			<div class="search">
				<img src="images/search.png" alt="Search" class="search-icon">
			</div>
			<img src="images/cross-white.png" alt="cross" class="close-icon">
		</div>
</div>
</header>
<!-- =========Mobile Menu============ -->
<header class="mobile-menu">
	<a href="index.html"><img src="images/logo.svg" alt="Logo"></a>
	<input type="checkbox" id="main-nav-check" />
<div id="menu">
<label for="main-nav-check" class="toggle" onclick="" title="Close">&times;</label>
<ul>
	<li><a href="index.html">Home</a></li>
	<li><a href="introduction.html">Introduction</a> <label for="fof" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
		<input type="checkbox" id="fof" class="sub-nav-check" />
		<ul id="fof-sub" class="sub-nav">
			<li class="sub-heading">Introduction <label for="fof" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
			<li><a href="structure.html">0.1 Structure</a></li>
			<li><a href="how-was-the-report-written.html">0.2 How was the Report Written?</a></li>
			<li><a href="what-recommendations-does-the-report-make.html">0.3 What Recommendations Does the Report Make?</a></li>
			<li><a href="a-note-on-terminology.html">0.4 A Note on Terminology</a></li>
			<li><a href="minding-language-about-mental-health-and-technology.html">0.5 Minding Language about Mental Health and Technology</a></li>
		</ul>
	</li>
	<li><a href="rising-automation-in-mental-health.html">Rising Automation in Mental Health</a> <label for="fast-apps" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
		<input type="checkbox" id="fast-apps" class="sub-nav-check" />
		<ul id="fast-apps-sub" class="sub-nav">
			<li class="sub-heading">Rising Automation in Mental Health <label for="fast-apps" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
			<li><a href="crisis-support-and-mental-health-care.html">1.1 What are the different ways technology is used in crisis support and mental health care?</a></li>
			<li><a href="benefits-noted-in-research.html">1.2 Benefits Noted in Research</a></li>
			<li><a href="psychiatric-intervention-and-Other-coercive-measures.html">1.3 Digitising Involuntary Psychiatric Intervention and Other Coercive Measures</a> <label for="fof-portfolio" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="fof-portfolio" class="sub-nav-check" />
				<ul id="fof-portfolio-sub" class="sub-nav">
					<li class="sub-heading">1.3 Digitising Involuntary Psychiatric Intervention and Other Coercive Measures <label for="fof-portfolio" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="ai-based-suicide-alerts-and-self-harm-surveillance.html">1.3.1 AI-based Suicide Alerts and Self-harm Surveillance</a></li>
					<li><a href="digitising-mental-health-law.html">1.3.2 ‘Digitising mental health law’</a></li>
					<li><a href="power-and-coercion-in-mental-health.html">1.3.3 Power and Coercion in Mental Health</a></li>
				</ul>
			</li>
			<li><a href="biometric-monitoring-technologies.html">1.4 Biometric Monitoring Technologies</a> <label for="fof-services" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="fof-services" class="sub-nav-check" />
				<ul id="fof-services-sub" class="sub-nav">
					<li class="sub-heading">1.4 Biometric Monitoring Technologies <label for="fof-services" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="biometric-and-digital-turn.html">1.4.1 Power and Justice in the Biometric and Digital Turn</a></li>
					<li><a href="biometric-monitoring-in-mental-health-settings.html">1.4.2 Governing the Future of Biometric Monitoring in Mental Health Settings</a></li>
				</ul>
			</li>
			<li><a href="experience-of-extreme-distress-and-disability.html">1.5 Elevating the Perspective of People with Lived Experience of Extreme Distress and Disability</a></li>
		</ul>
	</li>
	<li><a href="themes-for-public-governance.html">Themes for Public Governance</a> <label for="public-apps" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
		<input type="checkbox" id="public-apps" class="sub-nav-check" />
		<ul id="public-apps-sub" class="sub-nav">
			<li class="sub-heading">Themes for Public Governance<label for="public-apps" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
			<li><a href="privacy.html">2.1 Privacy</a> <label for="public-portfolio" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-portfolio" class="sub-nav-check" />
				<ul id="public-portfolio-sub" class="sub-nav">
					<li class="sub-heading">2.1 Privacy <label for="public-portfolio" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="ad-tech-and-predictive-public-health-surveillance.html">2.1.1 Ad-Tech and Predictive Public Health Surveillance</a></li>
					<li><a href="privacy-and-monetisation-of-sensitive-personal-data.html">2.1.2 Privacy and Monetisation of Sensitive Personal Data</a></li>
					<li><a href="data-theft-and-data-trafficking.html">2.1.3 Data Theft and Data Trafficking</a></li>
					<li><a href="privacy-and-discrimination.html">2.1.4 Privacy and Discrimination</a></li>
					<li><a href="data-protection-law.html">2.1.5 Data Protection Law</a></li>
					<li><a href="informed-consent.html">2.1.6 Informed Consent</a></li>
				</ul>
			</li>
			<li><a href="accountability.html">2.2 Accountability</a> <label for="public-acc" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-acc" class="sub-nav-check" />
				<ul id="public-acc-sub" class="sub-nav">
					<li class="sub-heading">2.2 Accountability <label for="public-acc" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="privatisation-and-accountability.html">2.2.1 Privatisation and Accountability</a></li>
				</ul>
			</li>
			<li><a href="safety-and-security.html">2.3 Safety and security</a> <label for="public-Safety-security" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-Safety-security" class="sub-nav-check" />
				<ul id="public-Safety-security-sub" class="sub-nav">
					<li class="sub-heading">2.2 Accountability <label for="public-Safety-security" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="safety.html">2.3.1 Safety</a></li>
					<li><a href="security.html">2.3.2 Security</a></li>
				</ul>
			</li>
			<li><a href="non-discrimination-and-equity.html">2.4 Non-Discrimination and Equity</a> <label for="public-equity" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-equity" class="sub-nav-check" />
				<ul id="public-equity-sub" class="sub-nav">
					<li class="sub-heading">2.4 Non-Discrimination and Equity <label for="public-equity" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="non-discrimination-and-the-prevention-of-bias.html">2.4.1 Non-discrimination and the Prevention of Bias</a></li>
					<li><a href="fairness.html">2.4.2 Fairness</a></li>
					<li><a href="equality.html">2.4.3 Equality</a></li>
					<li><a href="inclusive-design.html">2.4.4 Inclusive Design – Emancipatory? Participatory?</a></li>
					<li><a href="access-to-technology.html">2.4.5 Access to Technology</a></li>
				</ul>
			</li>

			<li><a href="human-control-of-technology.html">2.5 Human control of technology</a> <label for="public-human" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-human" class="sub-nav-check" />
				<ul id="public-human-sub" class="sub-nav">
					<li class="sub-heading">2.5 Human control of technology <label for="public-human" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="human-review-of-automated-decision.html">2.5.1 Human Review of Automated Decision</a></li>
					<li><a href="automated-decision-making.html">2.5.2 Ability to Opt-Out of Automated Decision-Making</a></li>
				</ul>
			</li>
			<li><a href="professional-responsibility.html">2.6 Professional responsibility</a> <label for="public-profess" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-profess" class="sub-nav-check" />
				<ul id="public-profess-sub" class="sub-nav">
					<li class="sub-heading">>2.6 Professional responsibility <label for="public-profess" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="multi-disciplinary-and-participatory-collaboration.html">2.6.1 Multi-disciplinary and Participatory Collaboration</a></li>
					<li><a href="scientific-integrity.html">2.6.2 Scientific Integrity and Testing Claims</a></li>
					<li><a href="techno-solutionism.html">2.6.3 Against Hype and ‘Techno-solutionism’</a></li>
					<li><a href="responsible-design.html">2.6.4 Responsible Design, Including Consideration of Long-Term Effects</a></li>
				</ul>
			</li>
			<li><a href="transparency-and-explainability.html">2.7 Transparency and explainability</a> <label for="public-trans" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-trans" class="sub-nav-check" />
				<ul id="public-trans-sub" class="sub-nav">
					<li class="sub-heading">2.7 Transparency and explainability <label for="public-trans" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="open-source-data-and-algorithms.html">2.7.1 Open-Source Data and Algorithms</a></li>
					<li><a href="other-issues-of-transparency-and-explainability.html">2.7.2 Other Issues of Transparency and Explainability</a></li>
				</ul>
			</li>
			<li><a href="public-interest-and-societal-good.html">2.8 Promotion of Public Interest and Societal Good</a> <label for="public-promo" class="toggle-sub" onclick=""><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label>
				<input type="checkbox" id="public-promo" class="sub-nav-check" />
				<ul id="public-promo-sub" class="sub-nav">
					<li class="sub-heading">2.8 Promotion of Public Interest and Societal Good <label for="public-promo" class="toggle" onclick="" title="Back"><svg height="20" viewBox="0 0 48 48" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M17.17 32.92l9.17-9.17-9.17-9.17 2.83-2.83 12 12-12 12z"/><path d="M0-.25h48v48h-48z" fill="none"/></svg></label></li>
					<li><a href="automation.html">2.8.1 Automation, Undermining Face-to-Face Care, and the Risk of Depersonalisation</a></li>
					<li><a href="expanding-the-frame.html">2.8.2 Expanding the Frame from the Individual to the Social</a></li>
				</ul>
			</li>
			<li><a href="international-human-rights.html">2.9 International Human Rights</a></li>
			<li><a href="future-efforts.html">2.10 Future Efforts</a></li>
		</ul>
	</li>

</ul>
<div class="input-box">
	<input type="text" placeholder="" />
	<div class="search">
		<img src="images/search.png" alt="Search" class="search-icon">
	</div>
	<img src="images/cross-white.png" alt="cross" class="close-icon">
</div>
</div>
<div id="header">
	<label for="main-nav-check" class="toggle" onclick="" title="Menu">&#x2261;</label>
</div><!-- closing "#header" -->
</header>
	<!-- Content Area -->
	<div class="container">
		<div class="row">
			<main>
				<aside class="col-lg-3 col-12 sidebar-left">
					<ol>
						<li>
							<a href="about.html">About</a>
						</li>
						<li>
							<a href="foreword.html">Foreword</a>
						</li>
						<li>
							<a href="introduction.html" class="active">Introduction</a>
						</li>
						<li>
							<a href="recommendations.html">Recommendations</a>
						</li>
						<li>
							<a href="note-on-terminology.html">A note on Terminology</a>
						</li>
						<li>
							<a href="rising-automation-in-mental-health.html">Rising Automation in Mental Health</a>
						</li>
						<li>
							<a href="digitising-involuntary-psychiatric-intervention.html">digitising Involuntary Psychiatric Intervention</a>
						</li>
						<li>
							<a href="biometric-monitoring-technologies.html">Biometric Monitoring Technologies</a>
						</li>
						<li>
							<a href="distress-and-disability.html">Elevating the Perspective of People with Lived Experience of Extreme Distress and Disability</a>
						</li>
						<li>
							<a href="themes-for-public-governance.html">Themes for Public Governance</a>
						</li>
						<li>
							<a href="conclusion.html">Conclusion</a>
						</li>
					</ol>
				</aside>
				<section class="col-lg-9 col-12 sidebar-middle">
					<div class="content-pane2">
						<h2 id="part-test4sub">1.4.1 Power and Justice in the Biometric and Digital Turn</h2>
						<p>The rise of biometric monitoring in mental health care is being debated on several fronts.
							This includes contested claims about what ‘digital markers’ of behaviour can reveal.<sup>116</sup> Even
							the term ‘digital phenotyping’ is contested and terminology remains unsettled. David Mohr
							and colleagues raise concerns that the term fails to convey the reality that the practice
							constitutes surveillance over intimate aspects of a person’s life.<sup>117</sup> Mohr and colleagues,
							who ultimately endorse the potential value of the technology, state:</p>
						<div class="benifit-box">
							<ul>
								<li>[W]hat might the term digital phenotyping signal mean to those whose data are
									being used? That such sensing is medical and scientific, perhaps? That it is complex?
									It does not convey to the average person that we are engaging in a sensitive form of
									surveillance: collecting large amounts of data, and using those data to understand
									deeply personal things, such as how they sleep, where they go, how and when they
									communicate with others, or whether they may be experiencing a mental health
									condition.<sup>118</sup></li>
							</ul>
						</div>
						<p>The authors call for language that is more transparent about the intent and practice
							behind this technology, arguing the term ‘personal sensing’ is more appropriate. </p>
						<p>Other commentators have drawn attention to deeper issues of justice and power. The use
							of biometric technologies to purportedly infer a person’s mental state or characteristics,
							and its use in pervasive forms of monitoring and surveillance, have raised particular
							concern.<sup>119</sup> Leah Harris warns of biometric technologies developed by psychiatric or
							psychological professionals being used in forms of social control over marginalised
							individuals, not just in mental health settings, but also in prisons and other sites of carceral
							control, including in the ‘community’.<sup>120</sup> Harris refers to Michel Foucault’s theorisation
							of the Panopticon, discussing the way ‘power is based on both the ability to observe
							others and the knowledge obtained through that observation’.<sup>121</sup> The Panopticon was
							originally an architectural system and idea developed in the eighteenth century by Jeremy
							Bentham. Its purpose is to continuously observe prisoners in confinement. For Foucault,
							panopticism is a surveillance mechanism used to exert disciplinary power throughout
							society by professionals, bureaucracies, government agencies, market actors, and so on,
							by allowing for an ‘absolute and constant visibility surrounding the bodies of individuals’.<sup>122</sup></p>
						<p>Toward the end of his life, Michel Foucault conceptualised a shift in Western societies
							away from the dominance of disciplinary environments such as largescale psychiatric
							institutions, to systems of constant external surveillance. He wrote, ‘[o]ne also sees the
							spread of disciplinary procedures, not in the form of enclosed institutions, but as centres
							of observation disseminated throughout society’.<sup>123</sup> He charts these societal shifts toward
							forms of control that are less costly and complex to manage.<sup>124</sup> Harris relates panopticism to
							biometric monitoring in the mental health context, warning that ‘[t]here is always an inherent power imbalance between the “omnipresent” and “invisible” watchers and their
							“permanently visible” subjects’ and that such imbalances have been expressed in psychiatry
							historically through its role in governing a marginalised and oppressed group<sup>125</sup>. Harris’s
							framing has commonalities with broader critiques of the information economy in the current
							era, including Shoshanna Zuboff’s prominent characterisation of ‘surveillance capitalism’.<sup>126</sup></p>
		
						
						<div class="skydivbox">
							<h2>EXPLAINER: Zuboff’s ‘Surveillance capitalism’</h2>
							<p>Shoshana Zuboff describes surveillance capitalism as the market-driven process
								that turn personal thoughts, experiences and behaviours into data that is then
								commodified for marketing purposes.<sup>127</sup> Such processes rely on the increasing use
								of surveillance processes, through the collection of data, not just based on what a
								person ‘posts’ online, but from the ‘behavioral surplus data’ that emerges from how
								a person uses their digital technology. Biometric data, usage rates, the manner a
								person expresses themselves, all become converted into data that can be extracted
								and sold for value. Data is then on-sold with claims that it has predictive value for
								how someone may behave. Zuboff explains this extraction process within the context
								of a diabetes app: </p>
							<p class="sm-padd-gap">You download a diabetes app, it takes your phone, it takes your microphone,
								it takes your camera, it takes your contacts. Maybe it helps you manage your
								diabetes a little bit, but it’s also just a part of this whole supply-chain dynamic for
								behavioral surplus flows. The stuff that they’re taking from you has nothing to do
								with the diabetes functionality for which you downloaded the app. Absolutely
								nothing. It’s simply siphoning off data to third parties for other revenue streams
								that are part of these surveillance capitalists’ ecosystems.<sup>128</sup></p>
							<p>However, the market incentives that form under surveillance capitalism go beyond
								prediction, towards shaping or controlling behaviour, or as Zuboff describes, the
								creation of ‘monitoring and compliance regimes’.<sup>129</sup> That is, digital technologies can
								be integrated with other incentives to ensure behaviours that are compliant with
								businesses objectives, such as sharing additional data or maintaining engagement in
								order to continue having access to the full benefits of the technology. One example
								where this is used is the ‘internet of things’, whereby there is an integration between
								digital technologies and data with everyday objectives, such as those in a google
								home, or with a car. The failure to share data may disable features of ‘smart devices’
								in the home, or if payments run late on a car, it can be remotely disabled from
								operating any longer. Therefore there remains choice, but with significant tradeoffs. Individual consumers in this setting have little bargaining power compared to
								significant digital platforms.<sup>130</sup> The broader implications of these market incentives
								taken to their conclusion is the construction of a society that is in ‘perpetual
								compliance’ with business interests.<sup>131</sup></p>
						</div>
		
						<p>How might surveillance capitalism operate in the mental health context? Various critical
							accounts have been offered. Lisa Cosgrove and colleagues’ state:</p>
						<div class="benifit-box">
							<ul>
								<li>Mental health apps that use digital phenotyping and other surveillance technologies
									position people as unwitting profit-makers; they take individuals at their most
									vulnerable and make them part of a hidden supply chain for the marketplace.<sup>132</sup>
							</ul>
						</div>
						<p>Examples of such data-extraction are included throughout this paper. Jonah Bossewitch
							warns of the ‘arrival of surveillance psychiatry’ and queries its role in the growing
							information economy, whereby ‘huge pools of data are being used to train algorithms to
							identify signs of mental illness’:<sup>133</sup></p>
						<div class="benifit-box">
							<ul>
								<li>Researchers are claiming they can diagnose depression based on the color and
									saturation of photos in your Instagram feed and predict manic episodes based on
									your Facebook status updates. Corporations and governments are salivating at the
									prospect of identifying vulnerability and dissent. The emphasis on treating risk rather
									than disease predates the arrival of big data, but together they are now ushering in an
									era of algorithmic diagnosis based on the data mining of our social media and other
									digital trails.<sup>134</sup>
							</ul>
						</div>
						<p>One challenge for advocates will be to correctly identify the business models of
							companies generating or processing such data. Without transparency on this matter,
							which companies will not necessarily divulge, observers may be left to speculate. One
							obvious business model would be targeting platform users with commercial products, as
							the next example suggests.</p>
						<div class="skydivbox">
							<h2>CASE STUDY: ‘Cerebral’ – app company accused of ‘accelerating the psychiatric
								prescribing cascade’</h2>
							<p>A 2021 Bloomberg investigation of the popular mental health app ‘Cerebral’, for
								example, found evidence that it led to overtreatment that generated increased sales
								of home-delivered psychopharmaceutical prescriptions.<sup>135</sup> ‘Cerebral’ does not involve
								biomonitoring but it highlights a business model that others will be following in the
								industry, regardless of how data is generated. The Cerebral app provides a platform
								for connecting platform users to a therapist and a psychiatric nurse practitioner at a
								monthly cost.<sup>136</sup> Former Cerebral employees reported to journalists that the company
								prized quantity over quality, involving more patient visits, shorter appointments,
								and more prescriptions.<sup>137</sup> Concerns were raised about the app ‘accelerating the
								psychiatric prescribing cascade’ for people seeking amphetamines prescribed for
								ADHD.<sup>138</sup></p>
						</div>
						<p>We will discuss private sector interests and the role of data concerning mental health in
							the information economy throughout the report.</p>
				
						<p>Returning to biometric monitoring, others have raised concerns that people who use
							algorithmic interpretations of data concerning emotions are misled about the extent to
							which such systems can ‘capture’ the reality of emotional experiences.<sup>139</sup> Victoria Hollis and
							colleagues point to a survey of people (n=188) who showed strong interest in automatic
							stress and emotion tracking, where ‘many respondents expected these systems to provide
							objective measurements for their emotional experiences’ despite this simply not being
							possible.<sup>140</sup> This framing effect (which is often exaggerated by tech vendors) can even
							change the way people construe their own emotions. In another study, Hollis examined
							how algorithmic sensor feedback influences emotional self-judgments in a mixed-methods
							study with 64 participants.<sup>141</sup> ‘Despite users reporting strategies to test system outputs,
							users still deferred to feedback and their perceived emotions were significantly influenced
							by feedback frames’ with some users even ‘overr[iding] personal judgments, believing the
							system had access to privileged information about their emotions.<sup>142</sup></p>
						<p>Similarly, Lisa Parker and colleagues, in their survey of the messaging of mental health
							apps, argued that prominent apps tend to over-medicalise states of distress and may
							over-emphasise ‘individual responsibility for mental well-being’.<sup>143</sup> As a broad comment,
							the user/survivor/ex-patient movement and others have advanced reasons to demedicalise approaches to supporting people in distress; which would seemingly extend
							to caution about framing personal mental crises as medical problems amenable to
							digital technological solutions.<sup>144</sup>
							The framing effects of biometric monitoring often go
							unremarked, but the studies noted above suggest the effects can alienate people from
							their own self-perceptions. For their part, Hollis and colleagues argue that the framing
							effects of should be acknowledged and used in ways to promote agency and help
							individuals more actively construe their personal experiences.<sup>145</sup></p>
						<p>Concerns raised by Harris, Bossewitch and others move beyond questions of how to make
							particular technologies like biometric monitoring more equitable or ethical (for example,
							by ensuring the datasets adequately cover diverse communities that accommodate
							distinct ways of being and self-presenting). Instead, their questions relate to law and
							political economy, questioning whether technologies are creating a market for surveillance
							in the mental health context that perpetuates and even extends the worst power
							imbalances, inequities and harms of current mental health practices.<sup>146</sup> Kaitlin Costello and
							Diana Floegel, for example, argue that the ‘link between the carceral state and mental
							healthcare in the United States is alarming’ and that biometric monitoring technologies
							‘are poised to only further strengthen that link, despite calls to the contrary’.<sup>147</sup> More
							fundamentally, this new ensemble of AI and mental health looks set to change what it is to
							be considered well or unwell.<sup>148</sup></p>
					
						<p><strong>Moving the Frame from ‘What does the technology do?’ to ‘Who is benefiting and who
								is not?’</strong></p>
						<p>One analytical strategy to help counter these negative possibilities is to place the
							emphasis away from the technology itself and toward questions of who is benefiting from
							the push for these technologies, and – perhaps more importantly – who is losing. This
							framing challenges the common presentation of computational monitoring and evaluation
							as naturally being in people’s interests on the basis that ‘the more we know the more we
							can help’. Such an optimistic view can easily dovetail with widely-held understandings
							about the legitimacy and unquestioned benefit of monitoring persons experiencing
							distress, lived experience and disability. As Sharon Snyder and David Mitchell have argued,
							‘[o]ne of the primary oppressions experienced by disabled people is that they are marked
							as perpetually available for all kinds of intrusions, public and private.<sup>149</sup></p>
						<p>The broad group of critical commentators raising concerns with biometric monitoring
							draw attention to the potential intrinsic harms of processes of computational observation
							and measurement. Just as the ‘medical gaze’ has been used as a concept to critique the
							biomedical and individualistic framing of distress and other human experiences, some
							commentators have considered the potential harms of the ‘data gaze’. The ACLU, for
							example, describe a potential ‘nightmare scenario’ whereby a ‘data gaze’ extends to omni-present AI-powered monitoring and surveillance:</p>
						<div class="benifit-box">
							<ul>
								<li>the consistent tracking of our every conscious and unconscious behavior that,
									combined with our innate social selfconsciousness, turns us into quivering, neurotic
									beings living in a psychologically oppressive world in which we’re constantly
									aware that our every smallest move is being charted, measured, and evaluated
									against the like actions of millions of other people — and then used to judge us in
									unpredictable ways.<sup>150</sup>
							</ul>
						</div>
						<p>These concerns were not raised about the mental health context in particular, though they
							resonate with the concerns discussed in this section.</p>
						<p>Others have raised concerns about the subtle harms caused by the way technological
							surveillance leads to an abstraction of the human body, which is then reassembled
							through a series of data flows.<sup>151</sup> Jathan Sadowski has argued that the abstraction of
							‘datafication’ is itself a form of violence.<sup>152</sup> Extending these critiques to the disability
							context, Jackie Leach Scully and Georgia Van Toorn have argued that broader
							‘datafication’ of the human body will delineate increasingly rigid boundaries between
							normality and disability.<sup>153</sup> This impulse to quantify and distinguish embodied difference,
							they argue, ‘diverts attention from the realities of disabled lives, at a time when disability
							scholars and activists are arguing for more rather than less attention to the lived
							experience of disability’.<sup>154</sup> LLana James, discussing algorithmic racism and the impacts
							of the digital turn on other marginalised groups, has discussed how datafication can
							undermine the need to ‘act on the reliable narrator’ (that is, listening to the person or
							populations affected and how they articulate their needs).<sup>155</sup> Instead, dominant narratives
							about technology insist on new and alternative ways to undertake expert observation and monitoring using data-driven technology.<sup>156</sup> In the disability context, including the mental
							health context, the use of automation risks diverting attention from the experienced reality
							of disabled lives.<sup>157</sup></p>
						<p>If these concerns are taken seriously, the use of technologies like AI to make assumptions
							and judgements about who we are, and who we will become is much more than a
							potential invasion of privacy; it is an existential threat to human autonomy and the ability
							to explore, develop and express our identities. It is potentially a normalising of surveillance
							in a way that is reminiscent of 19<sup>th</sup> century asylums as a state-authorised site of control
							over disabled lives, but using 21<sup>st</sup> century techniques of ubiquitous observation and
							computational ‘processing’. Grappling with these possibilities will be a necessary part of
							discussion about the potential harms and public benefits afforded by technology in the
							mental health context in general, particularly biometric monitoring. </p>
							
						<h3 id="part-test4subtwo">1.4.2 Governing the Future of Biometric Monitoring in Mental
							Health Settings</h3>
						<p>Biometrics more generally are the subject of a growing field of research, practice,
							advocacy, activism, and law reform.<sup>158</sup> In healthcare, the COVID-19 pandemic has
							accelerated the international adoption of forms of biomonitoring and surveillance, and
							other public health monitoring and security technologies, whether adopted by states,
							private entities or individuals.<sup>159</sup></p>
						<p>In the mental health context, scholarship that explores the legal, ethical, social, and
							political concerns with biometric technologies is emerging.<sup>160</sup> More work is clearly
							required. Later themes discussed in this report will engage with some of the questions
							directly relevant to biometrics. Such questions include asking if those deemed through
							biometric monitoring to be ‘cognitively impaired’, ‘mentally disordered’, ‘suicidal’, or likely
							to become any of those things, will be informed that such attributions have been made.
							Will they be able to opt-out of the monitoring process in the first place? Will they be able
							to contest such labels before data are transferred to others? Given the purported ease
							with which mobile phone data-points can be used for automated profiling to determine
							cognitive impairment,<sup>161</sup> are there sufficient safeguards to govern whether or how this
							should occur? More pointedly, should moratoria apply to some forms of biometric
							monitoring and surveillance in the mental health and disability context on the basis that
							they are fundamentally harmful or inconsistent with human rights? How would such a
							decision be made? What role is currently being played by psychiatric and psychological
							sciences in advancing such technologies? What role should they play?</p>
						<p>This is a critical moment to reflect how the current choices being made in various
							institutions concerning ‘digital mental health’ – from research, services, policies and
							programming – might affect future approaches to distress, anguish, mental crises and
							so on. To conclude Part 1 we turn to the glaring omission from these choices of the very
							people for whom the technologies are purportedly designed</p>
						<div class="sm-txt">
							<ul>
								<li>116 Phoebe Friesen, ‘Digital Psychiatry: Promises and Perils’ (2020) 27(1) Association for the Advancement of Philosophy and Psychiatry 2; Mohr,
									Shilton and Hotopf (n 103); Eric S Swirsky and Andrew D Boyd, ‘Adherence, Surveillance, and Technological Hubris’ (2018) 18(9) The American
									Journal of Bioethics 61.</li>
								<li>117 Mohr, Shilton and Hotopf (n 103).</li>
								<li>118 Ibid.</li>
								<li>119 Jonah Bossewitch, ‘Brave New Apps: The Arrival of Surveillance Psychiatry’, Mad In America (9 August 2019) <a href="https://www.madinamerica.com/2019/08/brave-new-apps-the-arrival-of-surveillance-psychiatry/">https://www.madinamerica.com/2019/08/brave-new-apps-the-arrival-of-surveillance-psychiatry/</a>; Leah Harris, ‘The Rise of the Digital Asylum’, Mad In America (15
									September 2019) <a href="https://www.madinamerica.com/2019/09/the-rise-of-the-digital-asylum/">https://www.madinamerica.com/2019/09/the-rise-of-the-digital-asylum/</a>.</li>
								<li>120 Harris, ‘The Rise of the Digital Asylum’ (n 121); L Harris, ‘The New National Mental Health Crisis Line Wants to Track Your Location’, Disability
									Visibility Project (19 April 2021) <a href="https://disabilityvisibilityproject.com/2021/04/19/the-new-national-mental-health-crisis-line-wants-to-track-your-location/">https://disabilityvisibilityproject.com/2021/04/19/the-new-national-mental-health-crisis-line-wants-to-track-your-location/</a>.</li>
								<li>121 Harris, ‘The Rise of the Digital Asylum’ (n 121).</li>
								<li>122 Michel Foucault, Psychiatric power: Lectures at the Collège de France (Palgrave Macmillan, 2006), p.52.</li>
								<li>123 Michel Foucault, Discipline and punish: The birth of the prison (Vintage Books, 1995) p.212.</li>
								<li>124 Etienne Paradis-Gagné and Dave Holmes, ‘Gilles Deleuze’s Societies of Control: Implications for Mental Health Nursing and Coercive
									Community Care’ n/a(n/a) Nursing Philosophy e12375</li>
								<li>125 Harris, ‘The Rise of the Digital Asylum’ (n 121).</li>
								<li>126 Shoshana Zuboff, The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power: Barack Obama’s Books of
									2019 (Profile books, 2019).</li>
								<li>127 Ibid.</li>
								<li>128 Noah Kulwin, ‘Shoshana Zuboff Talks Surveillance Capitalism’s Threat to Democracy’, Intelligencer (24 February 2019) <a href="https://nymag.com/intelligencer/2019/02/shoshana-zuboff-q-and-a-the-age-of-surveillance-capital.html">https://nymag.com/intelligencer/2019/02/shoshana-zuboff-q-and-a-the-age-of-surveillance-capital.html</a>.</li>
								<li>132 Lisa Cosgrove et al, ‘Psychology and Surveillance Capitalism: The Risk of Pushing Mental Health Apps during the COVID-19 Pandemic’
									(2020) 60(5) Journal of Humanistic Psychology 611, 620.</li>
								<li>133 Bossewich (n 119).</li>
								<li>134 Ibid.</li>
								<li>135 ‘ADHD Drugs Are Convenient To Get Online. Maybe Too Convenient’, Bloomberg.com (online, 11 March 2022) <a href="https://www.bloomberg.com/news/features/2022-03-11/cerebral-app-over-prescribed-adhd-meds-ex-employees-say">https://www.bloomberg.com/news/features/2022-03-11/cerebral-app-over-prescribed-adhd-meds-ex-employees-say</a>.</li>
								<li>136 ‘How Mental Health Apps Can Accelerate the Psychiatric Prescribing Cascade’, Lown Institute (18 March 2022) <a href="https://lowninstitute.org/how-mental-health-apps-can-accelerate-the-psychiatric-prescribing-cascade/">https://lowninstitute.org/how-mental-health-apps-can-accelerate-the-psychiatric-prescribing-cascade/</a>.</li>
								<li>137 ‘ADHD Drugs Are Convenient To Get Online. Maybe Too Convenient’ (n 137).</li>
								<li>138 ‘How Mental Health Apps Can Accelerate the Psychiatric Prescribing Cascade’ (n 138).</li>
								<li>139 Victoria Hollis et al, ‘On Being Told How We Feel: How Algorithmic Sensor Feedback Influences Emotion Perception’ (2018) 2(3)
									Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 114:1-114:31.</li>
								<li>140 Ibid.</li>
								<li>141 Ibid.</li>
								<li>142 Ibid.</li>
								<li>143 Lisa Parker et al, ‘Mental Health Messages in Prominent Mental Health Apps’ (2018) 16(4) The Annals of Family Medicine 338.</li>
								<li>144 China Mills and Eva Hilberg, ‘The Construction of Mental Health as a Technological Problem in India’ (2020) 30(1) Critical Public Health 41.
									Nev Jones, for example, has examined the impact of other ways of scientifically framing mental distress, including genetic and neurobiological
									causal attributions of psychiatric disorder, which she warns can undercut the agency of people in distress and the nuance of the individual
									experiences. Nev Jones, ‘Agency, Biogenetic Discourse and Psychiatric Disorder’, Somatosphere (18 September 2012) <a href="http://somatosphere.net/2012/agency-biogenetic-discourse-and-psychiatric-disorder.html/">http://somatosphere.net/2012/agency-biogenetic-discourse-and-psychiatric-disorder.html/</a>.</li>
								<li>145 Hollis et al (n 141).</li>
								<li>146 Harris, ‘The Rise of the Digital Asylum’ (n 121). This broader point was made by Frank Pasquale (see above n 6).</li>
								<li>147 Kaitlin L Costello and Diana Floegel, ‘“Predictive Ads Are Not Doctors”: Mental Health Tracking and Technology Companies’ (2020) 57(1)
									Proceedings of the Association for Information Science and Technology e250.</li>
								<li>148 Dan McQuillan, ‘Mental Health and Artificial Intelligence: Losing Your Voice’ (12 November 2018) openDemocracy <a href="https://www.opendemocracy.net/en/digitaliberties/mental-health-and-artificial-intelligence-losing-your-voice-poem/">https://www.opendemocracy.net/en/digitaliberties/mental-health-and-artificial-intelligence-losing-your-voice-poem/</a>.</li>
								<li>149 Sharon L Snyder and David T Mitchell, Cultural Locations of Disability (University of Chicago Press, 2006) p.628.</li>
								<li>150 Jay Stanley, The Dawn of Robot Surveillance: AI, Video Analytics, and Privacy (American Civil Liberties Union, 2019) 36.</li>
								<li>151 Kevin D. Haggerty and Richard V. Ericson, ‘The Surveillant Assemblage’ (2000) 51 British Journal of Sociology 611; R.E. Smith, Rage inside
									the machine: The prejudice of algorithms, and how to stop the internet making bigots of us all (Bloomsbury Academic, 2019).</li>
								<li>152 Jathan Sadowski, Too Smart: How Digital Capitalism Is Extracting Data, Controlling Our Lives, and Taking Over the World (MIT Press, 2020) 46.</li>
								<li>153 Jackie Scully and Georgia Van Toorn, ‘Datafying Disability: Ethical Issues in Automated Decision Making and Related Technologies –
									AABHL 2021’ (19 November 2021) <a href="http://www.aabhlconference.com/3563">http://www.aabhlconference.com/3563</a></li>
								<li>154 Ibid.</li>
								<li>155 LLana James, ‘Race-Based COVID-19 Data May Be Used to Discriminate against Racialized Communities’, The Conversation (15 September
									2020) <a href="http://theconversation.com/race-based-covid-19-data-may-be-used-to-discriminate-against-racialized-communities-138372">http://theconversation.com/race-based-covid-19-data-may-be-used-to-discriminate-against-racialized-communities-138372</a>.</li>
								<li>156 Schulich Law, Algorithmic Racism, Healthcare & The Law: ‘Race Based’ Data Another Trojan Horse? (19 September 2020) <a href="https://www.youtube.com/watch?v=PveOVJYIu3I">https://www.youtube.com/watch?v=PveOVJYIu3I</a>.</li>
								<li>157 Scully and Van Toorn (n 155).</li>
								<li>158 Kak (n 100).</li>
								<li>159 ‘Covid-19 Is Accelerating the Surveillance State’, The Strategist (17 November 2020) 19 <a href="https://www.aspistrategist.org.au/covid-19-is-accelerating-the-surveillance-state/">https://www.aspistrategist.org.au/covid-19-is-accelerating-the-surveillance-state/</a>; ‘Homo Deus Author Yuval Harari Shares Pandemic Lessons from Past and Warnings for Future’, South
									China Post (online, 1 April 2020) <a href="https://www.scmp.com/news/china/article/3077960/homo-deus-author-yuval-harari-shares-pandemic-lessons-past-and-warnings?fbclid=IwAR2b6pMEt1Gj4mpsBjSapqwL79e_tg_76eL4MLL788WYGDgTGRDbkM1H8y8">https://www.scmp.com/news/china/article/3077960/homo-deus-author-yuval-harari-shares-pandemic-lessons-past-and-warnings?fbclid=IwAR2b6pMEt1Gj4mpsBjSapqwL79e_tg_76eL4MLL788WYGDgTGRDbkM1H8y8</a>.</li>
								<li>160 See e.g. Cosgrove et al (n 98); Bossewitch, ‘The Rise of Surveillance Psychiatry and the Mad Underground’ (n 133); Harris, ‘The Rise of the Digital Asylum’ (n 119).</li>
								<li>161 Jonas Rauber, Emily B Fox and Leon A Gatys, ‘Modeling Patterns of Smartphone Usage and Their Relationship to Cognitive Health’ [2019]
									arXiv:1911.05683 [cs, stat] <a href="http://arxiv.org/abs/1911.05683">http://arxiv.org/abs/1911.05683</a></li>
							</ul>
						</div>
					</div>
				</section>
			</main>
		</div>
	</div>
	<!-- Footer Area -->
	<footer>
		<article class="foot-top">
			<div class="container">
				<div class="row">
					<div class="foot-top-area">
						<div class="arrow-plc">
							<a href="index.html" rel="prev">
							<div class="icon-area">
								<svg xmlns="http://www.w3.org/2000/svg" width="18.414" height="12.828" viewBox="0 0 18.414 12.828">
									<g id="Group_11" data-name="Group 11" transform="translate(282.914 497.914) rotate(180)">
									  <line id="Line_1" data-name="Line 1" x2="16" transform="translate(265.5 491.5)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
									  <line id="Line_2" data-name="Line 2" x2="5" y2="5" transform="translate(276.5 486.5)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
									  <line id="Line_3" data-name="Line 3" y1="5" x2="5" transform="translate(276.5 491.5)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
									</g>
								  </svg>
							</div>
							<div class="foot-title prev">
								<div class="foot-direction"><a href="biometric-monitoring-technologies.html">Previous</a></div>
								<div class="foot-link"><a href="biometric-monitoring-technologies.html">Biometric Monitoring Technologies</a></div>
							</div>
							</a>
						</div>
						<div class="arrow-plc">
							<a href="index.html" rel="next">
								<div class="foot-title next">
									<div class="foot-direction"><a href="biometric-monitoring-in-mental-health-settings.html">Next</a></div>
									<div class="foot-link"><a href="biometric-monitoring-in-mental-health-settings.html">Governing the Future of Biometric Monitoring in Mental Health Settings</a></div>
								</div>
								<div class="icon-area">
									<svg xmlns="http://www.w3.org/2000/svg" width="18.414" height="12.828" viewBox="0 0 18.414 12.828">
										<g id="Group_11" data-name="Group 11" transform="translate(1 1.414)">
										  <line id="Line_1" data-name="Line 1" x2="16" transform="translate(0 5)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
										  <line id="Line_2" data-name="Line 2" y1="5" x2="5" transform="translate(11 5)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
										  <line id="Line_3" data-name="Line 3" x2="5" y2="5" transform="translate(11)" fill="none" stroke="#fff" stroke-linecap="round" stroke-width="2"/>
										</g>
									  </svg>
								</div>
							</a>
						</div>
				</div>
					</div>
					</div>
		</article>
		<article class="foot-bottom"><a href="https://www.suncoastwebsolutions.com.au/services/web-design">Website Design</a> | <a href="https://www.suncoastwebsolutions.com.au/services/domain-web-hosting">Website Hosting</a> | Copyright © 2023 All rights reserved​ <a href="#">Digital Futures in Mind</a></article>
		<div class="scroll-to-top-btn"><svg viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><defs><style>.cls-1{fill:none;stroke:#fff;stroke-linecap:round;stroke-linejoin:round;stroke-width:2px;}</style></defs><title/><g id="arrow-top"><line class="cls-1" x1="15.87" x2="16.13" y1="3" y2="29"/><line class="cls-1" x1="15.87" x2="20.91" y1="3" y2="6.95"/><line class="cls-1" x1="15.87" x2="10.91" y1="3" y2="7.05"/></g></svg></div>
</footer>
	
	
<script src="js/jquery.min.js"></script>
<script src="js/bootstrap5.js"></script>
<script src="js/global.js"></script>

</body>

</html>